{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../data\"\n",
    "test_file_path = os.path.join(data_folder, \"merged_instructions.csv\")\n",
    "df = pd.read_csv(test_file_path)\n",
    "df['english_instruction'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b28faa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_data = []\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    message = row['instruction']\n",
    "    model_id = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'\n",
    "\n",
    "    prompt = f\"You are a helpful assistant that generates code snippets based on user instructions.\" \\\n",
    "                \"The method signature should be according to the given in the example part.\\n\" \\\n",
    "                \"Use the following guidlines in generation: \\n\" \\\n",
    "                \" - Provide the code in the response only\\n\" \\\n",
    "                \" - Do not output any other texts or test cases results.\\n\" \\\n",
    "                \" - Include the necessary import statements on the top even if they are usually not needed like - re, typing, itertools, Split etc. \\n\" \\\n",
    "                \" - Do not include any comments in the code\\n\" \\\n",
    "                \" - Do not forget to consider the edge cases\\n\" \\\n",
    "                \" - Avoid recursion if possible\\n\" \\\n",
    "                \" - Lastly, verify the code has no compilations error and contains the necessary imports.\\n\"\n",
    "    \n",
    "    # Set up messages and system message\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": message\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    system = [\n",
    "        {\n",
    "            \"text\": prompt\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Send the message to the model, using a basic inference configuration.\n",
    "        response = client.converse(\n",
    "            modelId=model_id,\n",
    "            messages=messages,\n",
    "            system=system,\n",
    "            inferenceConfig={\n",
    "                \"maxTokens\": 1024, \n",
    "                \"temperature\": 0.5\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Extract and print the response text.\n",
    "        flag = False\n",
    "        for content_block in response[\"output\"][\"message\"][\"content\"]:\n",
    "            if content_block.get(\"text\"):\n",
    "                code_response = content_block.get(\"text\")\n",
    "                result_data.append({\n",
    "                    \"id\": row['id'],\n",
    "                    \"response\": code_response\n",
    "                })\n",
    "                flag = True\n",
    "\n",
    "        if not flag:\n",
    "            result_data.append({\n",
    "                    \"id\": row['id'],\n",
    "                    \"response\": \"\"\n",
    "                })\n",
    "\n",
    "    except (Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "\n",
    "    print(\"Completed:\", row['id'])\n",
    "    \n",
    "result_df = pd.DataFrame(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a json from the result_df\n",
    "result_json = result_df.to_json(orient=\"records\", indent=4)\n",
    "# save json in the data_folder os.path.join(data_folder, \"submission.json\")\n",
    "with open(\"claude_3.5_haiku_submission.json\", \"w\") as json_file:\n",
    "    json_file.write(result_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
